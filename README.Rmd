---
output: github_document
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "# "
)
```

# tidypubmed

The [PubMed] database at NCBI includes 30 million citations from biomedical and
life sciences journals. The abstracts and article metadata are easy to search using
the [rentrez] package, but parsing the [PubMed XML] can be challenging. The `tidypubmed`
package uses the [xml2] package to parse abstracts, MeSH terms, keywords, authors
and citation details into [tidy] datasets.

## Installation

Use [devtools] to install the package.

```{r install, eval=FALSE}
devtools::install_github("maia-sh/tidypubmed")
```


Search [PubMed] and download the results.  The two functions are wrappers for
`entrez_search` and `entrez_fetch` in [rentrez] and will also parse the results
into a `xml_nodeset` with PMID names.

```{r pmc_xml}
library(tidypubmed)
res <- pubmed_search("aquilegia[TITLE]")
aq <- pubmed_fetch(res)
```

Alternatively, you can download the raw xml and save to disk.

```{r pmc_xml_download, eval = FALSE}
download_pubmed(99999999,
                dir = here::here("data", "raw", "pubmed"),
                api_key = keyring::key_get("ncbi-pubmed")
)
```

You can use `purrr::walk` to download many records. 

```{r pmc_xml_download_batch, eval = FALSE}
purrr::walk(download_pubmed,
            dir = here::here("data", "raw", "pubmed"),
            api_key = keyring::key_get("ncbi-pubmed")
)
```

The package includes six functions to parse the article nodes.


|R function        |Description        |
|:-----------------|:------------------|
|`pubmed_table `   |Citation metadata  |
|`pubmed_abstract` |Abstract paragraphs|
|`pubmed_authors`  |Authors            |
|`pubmed_keywords` |Keywords           |
|`pubmed_mesh`     |MeSH terms         |
|`pubmed_databanks`|Databanks          |
|`pubmed_pubtypes` |Publication types  |

The package includes a wrapper function to parse a specified article node types from a single PubMed record. Similar to downloading, you can use `purrr::map_dfr` to parse many records.

```{r extract_all, eval = FALSE}

extract_pubmed(filepath =  = here::here("data", "raw", "pubmed", "99999999.xml"),
               datatype = "main", # one of c("main", "abstract", "databanks", "authors", "mesh", "keywords", "pubtypes"). "main" indicated `pubmed_table`
)

here::here("data", "raw", "pubmed") %>% 
  fs::dir_ls() %>% 
  purrr::map_dfr(extract_pubmed, datatype = "main")

```

Parse the authors, year, title, journal and other metadata into a table with one row per PMID.

```{r cite, echo=-1}
options(width=110)
x <- pubmed_table(aq)
x
count(x, journal, country, sort=TRUE)
```


Parse the abstracts and combine the label and paragraph into a single row per article.

```{r abstract1, echo=-1}
options(width=110)
x <- pubmed_abstract(aq)
x
mutate(x, text=ifelse(is.na(label), abstract, paste0(label, ": ", abstract))) %>%
  group_by(pmid) %>%
  summarize(abstract=paste(text, collapse=" ")) %>%
  arrange(desc(pmid))
```

Optionally, use the [tokenizers] package to split abstract paragraphs into
sentences.

```{r abstract2, echo=-1}
options(width=110)
pubmed_abstract(aq, sentence=TRUE)
```

List the authors and first affiliation and then replace five or more names with
et al.  The untidy author string is also included in the `pubmed_table` above.

```{r authors, echo=-1}
options(width=110)
x <- pubmed_authors(aq)
x
mutate(x, name=ifelse(lead(n) == 5, "et al", paste(last, initials))) %>%
  filter(n < 5) %>%
  group_by(pmid) %>%
  summarize(authors=paste(name, collapse=", "))
```

Check the keywords.

```{r key, echo=-1}
options(width=110)
x <- pubmed_keywords(aq)
x
```


Count the MeSH terms.

```{r mesh, echo=-1}
options(width=110)
x <- pubmed_mesh(aq)
x
mutate(x, mesh=gsub("\\*", "", mesh)) %>%
  count(mesh, sort=TRUE)
```

Inspect databanks.

``` {r databanks, echo=-1}
options(width=110)
x <- pubmed_databanks(aq)
x
count(x, pmid, databank, sort=TRUE)
```
Inspect publication types.

``` {r pubtypes, echo=-1}
options(width=110)
x <- pubmed_pubtypes(aq)
x
count(x, publication_type, sort=TRUE)
```

There are an number of additional nodes that can be parsed in the [PubMed XML].
Use `cat(as.character)` to view a single article (truncated below).

```{r cat}
# cat(as.character(aq[1]))
cat(substr(as.character(aq[1]),1,770))
```

Parse a specific node using the helper function `xml_tidy_text` and an xpath expression.

```{r xml_tidy}
xml_tidy_text(aq, "//Chemical/NameOfSubstance", "chemical")

xml_tidy_text(aq, "//Reference//ArticleId[@IdType='pubmed']", "cited")
```

[PubMed XML]: https://www.nlm.nih.gov/bsd/licensee/elements_descriptions.html
[tidy]: https://r4ds.had.co.nz/tidy-data.html
[rentrez]: https://github.com/ropensci/rentrez
[PubMed]: https://www.ncbi.nlm.nih.gov/pubmed/
[devtools]: https://github.com/r-lib/devtools
[tokenizers]: https://lincolnmullen.com/software/tokenizers/
[xml2]: https://github.com/r-lib/xml2
